# Venice AI API — Complete Reference (llms-full.txt)

> Venice is a privacy-first, uncensored AI API platform. OpenAI SDK-compatible — just change the base URL. Zero data retention on private models. Pay-as-you-go with USD, crypto, or DIEM staking.

Base URL: https://api.venice.ai/api/v1
Auth: Bearer token via `Authorization: Bearer <VENICE_API_KEY>`

---

## Quick Setup

```python
from openai import OpenAI
client = OpenAI(api_key="YOUR_KEY", base_url="https://api.venice.ai/api/v1")
```

```javascript
import OpenAI from 'openai';
const client = new OpenAI({ apiKey: 'YOUR_KEY', baseURL: 'https://api.venice.ai/api/v1' });
```

```bash
export VENICE_API_KEY="your-key"
curl https://api.venice.ai/api/v1/chat/completions \
  -H "Authorization: Bearer $VENICE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"venice-uncensored","messages":[{"role":"user","content":"Hello"}]}'
```

---

## Endpoints

### POST /chat/completions — Text Generation

Standard OpenAI-compatible chat completions with Venice extensions.

**Request Body:**
```json
{
  "model": "string (required) — model ID from /models",
  "messages": [
    {
      "role": "system|user|assistant|tool",
      "content": "string | array of content parts (for vision)"
    }
  ],
  "stream": "boolean (default: false)",
  "temperature": "number 0-2 (default: model-specific)",
  "max_tokens": "integer",
  "top_p": "number 0-1",
  "frequency_penalty": "number -2 to 2",
  "presence_penalty": "number -2 to 2",
  "stop": "string | string[]",
  "tools": "array of tool objects (for function calling)",
  "tool_choice": "auto|none|required|{type:'function',function:{name:'...'}}",
  "response_format": {
    "type": "json_schema",
    "json_schema": {
      "name": "string",
      "strict": true,
      "schema": "JSON Schema object"
    }
  },
  "venice_parameters": {
    "enable_web_search": "on|off|auto (default: off) — enable web search for this request. 'on' forces search, 'auto' lets model decide. Citations returned in first streaming chunk or response.",
    "enable_web_scraping": "boolean (default: false) — auto-detect and scrape URLs in the latest user message via Firecrawl",
    "enable_web_citations": "boolean (default: false) — when web search is enabled, request the LLM cite sources using ^index^ superscript format",
    "include_venice_system_prompt": "boolean (default: true) — whether to include Venice's default system prompts alongside your system prompts",
    "character_slug": "string — the public ID of a Venice character persona (discoverable on published character pages)",
    "strip_thinking_response": "boolean (default: false) — strip <think></think> blocks from reasoning model responses. Also available as a model feature suffix.",
    "disable_thinking": "boolean (default: false) — on supported reasoning models, disables thinking entirely and strips <think></think> blocks from the response"
  }
}
```

**Response (non-streaming):**
```json
{
  "id": "chatcmpl-...",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "venice-uncensored",
  "choices": [{
    "index": 0,
    "message": {"role": "assistant", "content": "..."},
    "finish_reason": "stop|length|tool_calls"
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

**Vision (multimodal) example:**
```json
{
  "model": "mistral-31-24b",
  "messages": [{
    "role": "user",
    "content": [
      {"type": "text", "text": "Describe this image"},
      {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
    ]
  }]
}
```

**Function Calling example:**
```json
{
  "model": "zai-org-glm-4.7",
  "messages": [{"role": "user", "content": "What's the weather in SF?"}],
  "tools": [{
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get current weather",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {"type": "string"}
        },
        "required": ["location"]
      }
    }
  }]
}
```

**Structured Output example:**
```json
{
  "model": "venice-uncensored",
  "messages": [{"role": "user", "content": "List 3 colors"}],
  "response_format": {
    "type": "json_schema",
    "json_schema": {
      "name": "color_list",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "colors": {"type": "array", "items": {"type": "string"}}
        },
        "required": ["colors"],
        "additionalProperties": false
      }
    }
  }
}
```

### POST /image/generate — Image Generation

**Request Body:**
```json
{
  "model": "string (required) — e.g. venice-sd35, qwen-image, hidream, flux-2-pro",
  "prompt": "string (required)",
  "negative_prompt": "string (optional)",
  "width": "integer (default: 1024, max varies by model)",
  "height": "integer (default: 1024)",
  "cfg_scale": "number (guidance scale, default: model-specific)",
  "seed": "integer (for reproducibility)",
  "style_preset": "string (optional style)",
  "format": "png|webp|jpeg (default: png)",
  "variants": "integer 1-4 (number of images to generate)",
  "safe_mode": "boolean (default: false)"
}
```

**Response:**
```json
{
  "images": ["base64-encoded-image-string"],
  "id": "img-...",
  "model": "venice-sd35"
}
```

### POST /image/edit — Image Editing (Inpainting)

**Request:** `{"prompt": "string", "image": "base64-string"}`
**Response:** Binary image data (PNG).
**Model:** Uses qwen-edit internally.

### POST /image/upscale — Image Upscaling

**Request:** `{"image": "base64-string", "scale": 2|4}`
**Response:** Binary image data.

### GET /image/styles — List Style Presets

Returns available style presets for image generation.

### POST /audio/speech — Text-to-Speech

**Request:**
```json
{
  "model": "tts-kokoro",
  "input": "string (text to speak)",
  "voice": "string — e.g. af_sky, af_nova, am_liam, bf_emma, zf_xiaobei, jm_kumo",
  "response_format": "mp3|wav|opus|flac (default: mp3)",
  "speed": "number 0.25-4.0 (default: 1.0)"
}
```

**Response:** Audio binary data.
**60+ multilingual voices available.**

### POST /audio/transcriptions — Speech-to-Text

**Request:** Multipart form data:
- `file`: Audio file (WAV, FLAC, MP3, M4A, AAC, MP4)
- `model`: `nvidia/parakeet-tdt-0.6b-v3`
- `response_format`: `json|text|srt|verbose_json|vtt`
- `timestamps`: `boolean` (word-level timing)

### POST /embeddings — Vector Embeddings

**Request:**
```json
{
  "model": "text-embedding-bge-m3",
  "input": "string | string[]",
  "encoding_format": "float|base64 (default: float)"
}
```

**Response:**
```json
{
  "data": [{"embedding": [0.1, -0.2, ...], "index": 0}],
  "model": "text-embedding-bge-m3",
  "usage": {"prompt_tokens": 5, "total_tokens": 5}
}
```

### POST /video/queue — Queue Video Generation

**Request:**
```json
{
  "model": "string (required) — e.g. wan-2.6-text-to-video, veo3-fast-text-to-video",
  "prompt": "string (required for text-to-video)",
  "image": "base64-string (required for image-to-video models)",
  "resolution": "480p|720p|1080p",
  "duration": "number (seconds)",
  "aspect_ratio": "16:9|9:16|1:1",
  "include_audio": "boolean (for supported models)"
}
```

**Response:** `{"id": "video-job-id", "status": "queued"}`

### GET /video/retrieve?id={job_id} — Check Video Status

**Response:** `{"id": "...", "status": "queued|processing|completed|failed", "url": "...", "eta_seconds": 30}`

### GET /video/quote — Get Video Price Quote

Query params: `model`, `resolution`, `duration`, `aspect_ratio`, `include_audio`
Returns estimated price before generation.

### GET /models — List All Models

Returns all available models with capabilities, pricing, and constraints.

### GET /models/traits — Get Model Traits

Returns trait information for all models (capabilities, features, constraints).

### GET /models/compatibility_mapping — Get Model Compatibility Mapping

Returns OpenAI-to-Venice model compatibility mapping for migration.

### GET /billing/usage — Get Billing Usage (Beta)

Returns usage data including timestamps, SKUs, pricing, and inference details (request ID, execution time, token counts).

### POST /images/generations — OpenAI-Compatible Image Generation

OpenAI-compatible image generation endpoint. Use this if migrating from OpenAI's DALL-E API.

### POST /video/complete — Complete Video

Marks a video generation job as complete/cleaned up.

### POST /api_keys — Create API Key
### GET /api_keys — List API Keys
### GET /api_keys/{id} — Get API Key
### PUT /api_keys/{id} — Update API Key
### DELETE /api_keys/{id} — Delete API Key
### GET /api_keys/{id}/rate_limits — Get Rate Limits
### GET /api_keys/{id}/rate_limit_logs — Get Rate Limit Logs

### GET /characters — List Characters
### GET /characters/{slug} — Get Character

---

## Text Models (with pricing per 1M tokens)

| Model | ID | Input | Output | Cache Read | Context | Capabilities |
|-------|-----|-------|--------|------------|---------|-------------|
| Venice Small | qwen3-4b | $0.05 | $0.15 | — | 33K | Function Calling, Reasoning |
| OpenAI GPT OSS 120B | openai-gpt-oss-120b | $0.07 | $0.30 | — | 131K | Function Calling (Beta) |
| Google Gemma 3 27B | google-gemma-3-27b-it | $0.12 | $0.20 | — | 203K | Function Calling, Vision |
| Qwen 3 235B Instruct | qwen3-235b-a22b-instruct-2507 | $0.15 | $0.75 | — | 131K | Function Calling |
| Llama 3.2 3B | llama-3.2-3b | $0.15 | $0.60 | — | 131K | Function Calling |
| Venice Uncensored 1.1 | venice-uncensored | $0.20 | $0.90 | — | 33K | Uncensored |
| Grok Code Fast 1 | grok-code-fast-1 | $0.25 | $1.87 | $0.03 | 262K | Function Calling, Reasoning, Code |
| Qwen3 VL 235B | qwen3-vl-235b-a22b | $0.25 | $1.50 | — | 262K | Function Calling, Vision |
| Qwen 3 Next 80b | qwen3-next-80b | $0.35 | $1.90 | — | 262K | Function Calling (Beta) |
| DeepSeek V3.2 | deepseek-v3.2 | $0.40 | $1.00 | $0.20 | 164K | Reasoning |
| MiniMax M2.1 | minimax-m21 | $0.40 | $1.60 | $0.04 | 203K | Function Calling, Reasoning, Code |
| Qwen 3 235B Thinking | qwen3-235b-a22b-thinking-2507 | $0.45 | $3.50 | — | 131K | Function Calling, Reasoning |
| Venice Medium | mistral-31-24b | $0.50 | $2.00 | — | 131K | Function Calling, Vision |
| Grok 4.1 Fast | grok-41-fast | $0.50 | $1.25 | $0.13 | 262K | Function Calling, Reasoning, Vision |
| GLM 4.7 | zai-org-glm-4.7 | $0.55 | $2.65 | $0.11 | 203K | Function Calling, Reasoning |
| Gemini 3 Flash | gemini-3-flash-preview | $0.70 | $3.75 | $0.07 | 262K | Function Calling, Reasoning, Vision |
| Llama 3.3 70B | llama-3.3-70b | $0.70 | $2.80 | — | 131K | Function Calling |
| Qwen 3 Coder 480b | qwen3-coder-480b-a35b-instruct | $0.75 | $3.00 | — | 262K | Function Calling, Code |
| Kimi K2 Thinking | kimi-k2-thinking | $0.75 | $3.20 | $0.38 | 262K | Function Calling, Reasoning, Code |
| Hermes 3 405b | hermes-3-llama-3.1-405b | $1.10 | $3.00 | — | 131K | (Beta) |
| GPT-5.2 | openai-gpt-52 | $2.19 | $17.50 | $0.22 | 262K | Function Calling, Reasoning |
| GPT-5.2 Codex | openai-gpt-52-codex | $2.19 | $17.50 | $0.22 | 262K | Function Calling, Reasoning, Vision, Code (Beta) |
| Gemini 3 Pro | gemini-3-pro-preview | $2.50 | $15.00 | $0.63 | 203K | Function Calling, Reasoning, Vision |
| Claude Sonnet 4.5 | claude-sonnet-45 | $3.75 | $18.75 | $0.38 | 203K | Function Calling, Reasoning, Vision, Code (Beta) |
| Claude Opus 4.5 | claude-opus-45 | $6.00 | $30.00 | $0.60 | 203K | Function Calling, Reasoning, Vision, Code |

## Image Models

| Model | ID | Per Image | Privacy |
|-------|-----|-----------|---------|
| Z-Image Turbo | z-image-turbo | $0.01 | Private |
| Venice SD35 | venice-sd35 | $0.01 | Private |
| HiDream | hidream | $0.01 | Private |
| Qwen Image | qwen-image | $0.01 | Private |
| Lustify SDXL | lustify-sdxl | $0.01 | Private |
| Lustify v7 | lustify-v7 | $0.01 | Private |
| Anime (WAI) | wai-Illustrious | $0.01 | Private |
| Background Remover | bg-remover | $0.02 | Anonymized |
| Flux 2 Pro | flux-2-pro | $0.04 | Anonymized |
| SeedreamV4.5 | seedream-v4 | $0.05 | Anonymized |
| Flux 2 Max | flux-2-max | $0.09 | Anonymized |
| Nano Banana Pro | nano-banana-pro | $0.18-$0.35 (resolution-based: 1K=$0.18, 2K=$0.24, 4K=$0.35) | Anonymized |
| GPT Image 1.5 | gpt-image-1-5 | $0.23 | Anonymized |

## Audio Models

| Model | ID | Pricing |
|-------|-----|---------|
| Kokoro TTS | tts-kokoro | $3.50/1M chars |
| Parakeet ASR | nvidia/parakeet-tdt-0.6b-v3 | $0.0001/audio sec |

## Embedding Models

| Model | ID | Input | Output |
|-------|-----|-------|--------|
| BGE-M3 | text-embedding-bge-m3 | $0.15/1M | $0.60/1M |

## Additional Pricing

- Web Search: $10.00/1K calls
- Web Scraping: $10.00/1K calls
- Image Upscaling: 2x=$0.02, 4x=$0.08
- Image Editing: $0.04/edit
- Video: Variable (use /video/quote API)

---

## Privacy Levels

- **Private**: Zero data retention. Prompts and outputs are never stored or logged. Full privacy.
- **Anonymized**: Processed by third-party providers. Venice strips identifying info but cannot guarantee provider behavior.

---

## Rate Limits (API Keys)

### Text Models

| Tier | RPM | TPM |
|------|-----|-----|
| XS (qwen3-4b, llama-3.2-3b, embeddings) | 500 | 1M |
| S (mistral-31-24b, venice-uncensored) | 75 | 750K |
| M (llama-3.3-70b, qwen3-next-80b, gemma-3) | 50 | 750K |
| L (all flagship/large models) | 20 | 500K |

### Non-Text Models

| Type | RPM |
|------|-----|
| Image | 20 |
| Audio | 60 |
| Embedding | 500 |
| Video (queue) | 40 |
| Video (retrieve) | 120 |

Abuse protection: 20+ failed requests in 30s triggers a 30s block. Use exponential backoff for 429 errors. Check `x-ratelimit-reset-requests` header for retry timing.

---

## Venice Parameters (venice_parameters)

These are Venice-specific extensions passed alongside standard OpenAI parameters:

- `enable_web_search`: `"on"|"off"|"auto"` (default: `"off"`) — Enable real-time web search. `"on"` forces search, `"auto"` lets the model decide. Citations returned in first streaming chunk or non-streaming response.
- `enable_web_scraping`: `boolean` (default: `false`) — Auto-detect and scrape URLs in the latest user message via Firecrawl.
- `enable_web_citations`: `boolean` (default: `false`) — When web search is enabled, request the LLM cite sources using `^index^` superscript format.
- `include_venice_system_prompt`: `boolean` (default: `true`) — Whether to include Venice's default system prompts alongside your specified system prompts.
- `character_slug`: `string` — The public ID of a Venice character persona (discoverable on published character pages).
- `strip_thinking_response`: `boolean` (default: `false`) — Strip `<think></think>` blocks from reasoning model responses. Also available as a model feature suffix.
- `disable_thinking`: `boolean` (default: `false`) — On supported reasoning models, disables thinking entirely and strips `<think></think>` blocks from the response.

**Python extra_body syntax:**
```python
completion = client.chat.completions.create(
    model="venice-uncensored",
    messages=[...],
    extra_body={"venice_parameters": {"enable_web_search": "auto"}}
)
```

**JavaScript syntax:**
```javascript
const completion = await client.chat.completions.create({
    model: 'venice-uncensored',
    messages: [...],
    venice_parameters: { enable_web_search: 'auto' }
});
```

---

## Migration from OpenAI

Venice is a drop-in replacement for OpenAI. Change two things:

1. `base_url` → `https://api.venice.ai/api/v1`
2. `api_key` → your Venice API key

**Model mapping suggestions:**
- GPT-4o → `zai-org-glm-4.7` (private) or `openai-gpt-52` (anonymized)
- GPT-4o-mini → `qwen3-4b` or `mistral-31-24b`
- GPT-4-vision → `mistral-31-24b` or `qwen3-vl-235b-a22b`
- o1/o3 → `qwen3-235b-a22b-thinking-2507` (private) or `grok-41-fast`
- text-embedding-3-small → `text-embedding-bge-m3`
- DALL-E 3 → `qwen-image` or `flux-2-pro`
- Whisper → `nvidia/parakeet-tdt-0.6b-v3`
- TTS → `tts-kokoro`

---

## Common Patterns

### Streaming
```python
stream = client.chat.completions.create(model="venice-uncensored", messages=[...], stream=True)
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### Multi-turn conversation
```python
messages = [{"role": "system", "content": "You are helpful."}]
messages.append({"role": "user", "content": "What is Venice AI?"})
response = client.chat.completions.create(model="venice-uncensored", messages=messages)
messages.append({"role": "assistant", "content": response.choices[0].message.content})
messages.append({"role": "user", "content": "Tell me more about privacy."})
# Continue with updated messages array...
```

### RAG with Embeddings
```python
# Generate embeddings
embedding = client.embeddings.create(model="text-embedding-bge-m3", input="your text")
vector = embedding.data[0].embedding  # Use with your vector DB

# Query with context
context = "Retrieved document text..."
response = client.chat.completions.create(
    model="venice-uncensored",
    messages=[
        {"role": "system", "content": f"Answer based on this context:\n{context}"},
        {"role": "user", "content": "User question"}
    ]
)
```

---

## Error Codes

| Code | Meaning |
|------|---------|
| 400 | Bad Request — Invalid parameters |
| 401 | Unauthorized — Invalid or missing API key |
| 403 | Forbidden — Insufficient permissions |
| 404 | Not Found — Invalid endpoint or model |
| 429 | Rate Limited — Too many requests |
| 500 | Internal Server Error |
| 503 | Service Unavailable — Model temporarily down |

---

## Links

- API Docs: https://docs.venice.ai
- API Keys: https://venice.ai/settings/api
- Status: https://veniceai-status.com
- Discord: https://discord.gg/askvenice
- Twitter: https://x.com/AskVenice

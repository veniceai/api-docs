---
title: Getting Started
"og:title": "Quickstart - Get started with Venice API"
description: "Make your first API request in minutes"
---

Venice AI is a privacy-first API for building AI applications with no data retention and OpenAI-compatible endpoints. You get text generation, image creation, embeddings, and text-to-speech without the surveillance.

## Quickstart

<Steps>
  <Step title="Get your API key">
    Head to your [Venice API Settings](https://venice.ai/settings/api) and generate a new API key.

    For a detailed walkthrough with screenshots, check out the [API Key guide](/overview/guides/generating-api-key).
  </Step>

  <Step title="Set up your API key">
    Add your API key to your environment. You can export it in your shell:

    ```bash
    export VENICE_API_KEY='your-api-key-here'
    ```

    Or add it to a `.env` file in your project:

    ```bash
    VENICE_API_KEY=your-api-key-here
    ```
  </Step>

  <Step title="Install the SDK">
    Venice is OpenAI-compatible, so you can use the OpenAI SDK. If you prefer to use cURL or raw HTTP requests, you can skip this step.

    <CodeGroup>
      ```bash Python
      pip install openai requests
      ```

      ```bash Node.js
      npm install openai form-data
      ```
    </CodeGroup>

    **Note:** The `requests` library (Python) and `form-data` package (Node.js) are needed for image upload endpoints like image editing and upscaling.
  </Step>

  <Step title="Send your first request">
    <CodeGroup>
      ```python Python
      import os
      from openai import OpenAI

      client = OpenAI(
          api_key=os.getenv("VENICE_API_KEY"),
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "system", "content": "You are a helpful AI assistant"},
              {"role": "user", "content": "Why is privacy important?"}
          ]
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      import OpenAI from 'openai';

      const client = new OpenAI({
          apiKey: process.env.VENICE_API_KEY,
          baseURL: 'https://api.venice.ai/api/v1'
      });

      async function main() {
          const completion = await client.chat.completions.create({
              model: 'venice-uncensored',
              messages: [
                  { role: 'system', content: 'You are a helpful AI assistant' },
                  { role: 'user', content: 'Why is privacy important?' }
              ]
          });

          console.log(completion.choices[0].message.content);
      }

      main();
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "system", "content": "You are a helpful AI assistant"},
            {"role": "user", "content": "Why is privacy important?"}
          ]
        }'
      ```
    </CodeGroup>

    **Message roles:**
    - `system` - Instructions for how the model should behave
    - `user` - Your prompts or questions
    - `assistant` - Previous model responses (for multi-turn conversations)
    - `tool` - Function calling results (when using tools)
  </Step>

  <Step title="Choose your model (optional)">
    Venice has multiple models for different use cases. Popular choices:
    - `llama-3.3-70b` - Balanced performance, great for most use cases
    - `qwen3-235b` - Most powerful flagship model for complex tasks
    - `mistral-31-24b` - Vision + function calling support
    - `venice-uncensored` - No content filtering

    <Card title="View All Models" icon="database" href="/overview/models">
      Browse the complete list of models with pricing, capabilities, and context limits
    </Card>
  </Step>

  <Step title="Use Venice Parameters">
    You can choose to enable Venice-specific features like web search using `venice_parameters`:

    <CodeGroup>
      ```python Python
      import os
      from openai import OpenAI

      client = OpenAI(
          api_key=os.environ.get("VENICE_API_KEY"),
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "user", "content": "What are the latest developments in AI?"}
          ],
          extra_body={
              "venice_parameters": {
                  "enable_web_search": "auto",
                  "include_venice_system_prompt": True
              }
          }
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      import OpenAI from 'openai';

      const client = new OpenAI({
          apiKey: process.env.VENICE_API_KEY,
          baseURL: 'https://api.venice.ai/api/v1'
      });

      async function main() {
          const completion = await client.chat.completions.create({
              model: 'venice-uncensored',
              messages: [
                  { role: 'user', content: 'What are the latest developments in AI?' }
              ],
              venice_parameters: {
                  enable_web_search: 'auto',
                  include_venice_system_prompt: true
              }
          });

          console.log(completion.choices[0].message.content);
      }

      main();
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "user", "content": "What are the latest developments in AI?"}
          ],
          "venice_parameters": {
            "enable_web_search": "auto",
            "include_venice_system_prompt": true
          }
        }'
      ```
    </CodeGroup>

    See all [available parameters](https://docs.venice.ai/api-reference/api-spec#venice-parameters).
  </Step>

  <Step title="Enable streaming (optional)">
    Stream responses in real-time using `stream=True`:

    <CodeGroup>
      ```python Python
      import os
      from openai import OpenAI

      client = OpenAI(
          api_key=os.environ.get("VENICE_API_KEY"),
          base_url="https://api.venice.ai/api/v1"
      )

      stream = client.chat.completions.create(
          model="venice-uncensored",
          messages=[{"role": "user", "content": "Write a short story about AI"}],
          stream=True
      )

      for chunk in stream:
          if chunk.choices and chunk.choices[0].delta.content is not None:
              print(chunk.choices[0].delta.content, end="")
      ```

      ```javascript Node.js
      import OpenAI from 'openai';

      const client = new OpenAI({
          apiKey: process.env.VENICE_API_KEY,
          baseURL: 'https://api.venice.ai/api/v1'
      });

      async function main() {
          const stream = await client.chat.completions.create({
              model: 'venice-uncensored',
              messages: [{ role: 'user', content: 'Write a short story about AI' }],
              stream: true
          });

          for await (const chunk of stream) {
              if (chunk.choices && chunk.choices[0]?.delta?.content) {
                  process.stdout.write(chunk.choices[0].delta.content);
              }
          }
      }

      main();
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "user", "content": "Write a short story about AI"}
          ],
          "stream": true
        }'
      ```
    </CodeGroup>
  </Step>

  <Step title="Customize response behavior (optional)">
    Control how the model responds with parameters like temperature, max tokens, and more:

    <CodeGroup>
      ```python Python
      import os
      from openai import OpenAI

      client = OpenAI(
          api_key=os.environ.get("VENICE_API_KEY"),
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "system", "content": "You are a creative storyteller"},
              {"role": "user", "content": "Tell me a creative story"}
          ],
          temperature=0.8,
          max_tokens=500,
          top_p=0.9,
          frequency_penalty=0.5,
          presence_penalty=0.5,
          extra_body={
              "venice_parameters": {
                  "include_venice_system_prompt": False
              }
          }
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      async function main() {
          const response = await fetch('https://api.venice.ai/api/v1/chat/completions', {
              method: 'POST',
              headers: {
                  'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
                  'Content-Type': 'application/json'
              },
              body: JSON.stringify({
                  model: 'venice-uncensored',
                  messages: [
                      { role: 'system', content: 'You are a creative storyteller' },
                      { role: 'user', content: 'Tell me a creative story' }
                  ],
                  temperature: 0.8,
                  max_tokens: 500,
                  top_p: 0.9,
                  frequency_penalty: 0.5,
                  presence_penalty: 0.5,
                  venice_parameters: {
                      include_venice_system_prompt: false
                  }
              })
          });

          const result = await response.json();
          console.log(result.choices[0].message.content);
      }

      main();
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "system", "content": "You are a creative storyteller"},
            {"role": "user", "content": "Tell me a creative story"}
          ],
          "temperature": 0.8,
          "max_tokens": 500,
          "top_p": 0.9,
          "frequency_penalty": 0.5,
          "presence_penalty": 0.5,
          "stream": false,
          "venice_parameters": {
            "include_venice_system_prompt": false
          }
        }'
      ```
    </CodeGroup>

    Check out the [Chat Completions docs](/api-reference/endpoint/chat/completions) for more information on all supported parameters.
  </Step>
</Steps>

---

## More Capabilities

### Image Generation

Create images from text prompts using diffusion models:

<CodeGroup>
  ```python Python
  import os
  import requests

  response = requests.post(
      "https://api.venice.ai/api/v1/image/generate",
      headers={
          "Authorization": f"Bearer {os.getenv('VENICE_API_KEY')}",
          "Content-Type": "application/json"
      },
      json={
          "model": "venice-sd35",
          "prompt": "A cyberpunk city with neon lights and rain",
          "width": 1024,
          "height": 1024
      }
  )

  result = response.json()
  print(result)
  ```

  ```javascript Node.js
  async function main() {
      const response = await fetch('https://api.venice.ai/api/v1/image/generate', {
          method: 'POST',
          headers: {
              'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              model: 'venice-sd35',
              prompt: 'A cyberpunk city with neon lights and rain',
              width: 1024,
              height: 1024
          })
      });

      const result = await response.json();
      console.log(result);
  }

  main();
  ```

  ```bash cURL
  curl https://api.venice.ai/api/v1/image/generate \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "venice-sd35",
      "prompt": "A cyberpunk city with neon lights and rain",
      "width": 1024,
      "height": 1024
    }'
  ```
</CodeGroup>

**Popular Image Models:**
- `qwen-image` - Highest quality image generation
- `venice-sd35` - Default choice with Eliza integration
- `flux-dev` - High-quality FLUX standard model

<Card title="View All Image Models" icon="image" href="/overview/models#image-models">
  See all available image models with pricing and capabilities
</Card>

**Note:** This example shows the basic parameters to get you started quickly. For advanced options like `cfg_scale`, `negative_prompt`, `style_preset`, `seed`, `variants`, and more, check out the [Image Generation API](/api-reference/endpoint/image/generate).

### Image Editing

Modify existing images with AI-powered inpainting using the Qwen-Image model:

<CodeGroup>
  ```python Python
  import os
  import requests
  import base64

  with open("image.png", "rb") as f:
      image_base64 = base64.b64encode(f.read()).decode('utf-8')

  response = requests.post(
      "https://api.venice.ai/api/v1/image/edit",
      headers={
          "Authorization": f"Bearer {os.getenv('VENICE_API_KEY')}",
          "Content-Type": "application/json"
      },
      json={
          "prompt": "Colorize",
          "image": image_base64
      }
  )

  print(response.json())
  ```

  ```javascript Node.js
  import fs from 'fs';

  async function main() {
      const imageBuffer = fs.readFileSync('image.png');
      const imageBase64 = imageBuffer.toString('base64');

      const response = await fetch('https://api.venice.ai/api/v1/image/edit', {
          method: 'POST',
          headers: {
              'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              prompt: 'Colorize',
              image: imageBase64
          })
      });

      const result = await response.json();
      console.log(result);
  }

  main();
  ```

  ```bash cURL
  curl --request POST \
    --url https://api.venice.ai/api/v1/image/edit \
    --header "Authorization: Bearer $VENICE_API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
      "prompt": "Colorize",
      "image": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAAIGNIUk0A..."
    }'
  ```
</CodeGroup>

**Note:** The image editor uses the Qwen-Image model and is an experimental endpoint. The image must be provided as a base64-encoded string.

See the [Image Edit API](/api-reference/endpoint/image/edit) for all parameters.

### Image Upscaling

Enhance and upscale images to higher resolutions:

<CodeGroup>
  ```python Python
  import os
  import requests
  import base64

  with open("image.png", "rb") as f:
      image_base64 = base64.b64encode(f.read()).decode('utf-8')

  response = requests.post(
      "https://api.venice.ai/api/v1/image/upscale",
      headers={
          "Authorization": f"Bearer {os.getenv('VENICE_API_KEY')}",
          "Content-Type": "application/json"
      },
      json={
          "enhance": True,
          "enhancePrompt": "gold",
          "image": image_base64,
          "scale": 2
      }
  )

  print(response.json())
  ```

  ```javascript Node.js
  import fs from 'fs';

  async function main() {
      const imageBuffer = fs.readFileSync('image.png');
      const imageBase64 = imageBuffer.toString('base64');

      const response = await fetch('https://api.venice.ai/api/v1/image/upscale', {
          method: 'POST',
          headers: {
              'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              enhance: true,
              enhancePrompt: 'gold',
              image: imageBase64,
              scale: 2
          })
      });

      const result = await response.json();
      console.log(result);
  }

  main();
  ```

  ```bash cURL
  curl --request POST \
    --url https://api.venice.ai/api/v1/image/upscale \
    --header "Authorization: Bearer $VENICE_API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
      "enhance": true,
      "enhancePrompt": "gold",
      "image": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAAIGNIUk0A...",
      "scale": 2
    }'
  ```
</CodeGroup>

**Note:** The image must be provided as a base64-encoded string. The `enhance` parameters allow for AI-powered enhancement during upscaling.

See the [Image Upscale API](/api-reference/endpoint/image/upscale) for all parameters.

### Text-to-Speech

Convert text to audio with 60+ multilingual voices:

<CodeGroup>
  ```python Python
  import os
  import requests

  response = requests.post(
      "https://api.venice.ai/api/v1/audio/speech",
      headers={
          "Authorization": f"Bearer {os.getenv('VENICE_API_KEY')}",
          "Content-Type": "application/json"
      },
      json={
          "input": "Hello, welcome to Venice Voice.",
          "model": "tts-kokoro",
          "voice": "af_sky"
      }
  )

  with open("speech.mp3", "wb") as f:
      f.write(response.content)
  ```

  ```javascript Node.js
  import fs from 'fs';

  async function main() {
      const response = await fetch('https://api.venice.ai/api/v1/audio/speech', {
          method: 'POST',
          headers: {
              'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              input: 'Hello, welcome to Venice Voice.',
              model: 'tts-kokoro',
              voice: 'af_sky'
          })
      });

      const audioBuffer = await response.arrayBuffer();
      fs.writeFileSync('speech.mp3', Buffer.from(audioBuffer));
  }

  main();
  ```

  ```bash cURL
  curl --request POST \
    --url https://api.venice.ai/api/v1/audio/speech \
    --header "Authorization: Bearer $VENICE_API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
      "input": "Hello, welcome to Venice Voice.",
      "model": "tts-kokoro",
      "voice": "af_sky"
    }' \
    --output speech.mp3
  ```
</CodeGroup>

The `tts-kokoro` model supports 60+ multilingual voices including `af_sky`, `af_nova`, `am_liam`, `bf_emma`, `zf_xiaobei`, and `jm_kumo`.

See the [TTS API](/api-reference/endpoint/audio/speech) for all voice options.

### Embeddings

Generate vector embeddings for semantic search, RAG, and recommendations:

<CodeGroup>
  ```python Python
  import os
  from openai import OpenAI

  client = OpenAI(
      api_key=os.getenv("VENICE_API_KEY"),
      base_url="https://api.venice.ai/api/v1"
  )

  response = client.embeddings.create(
      model="text-embedding-bge-m3",
      input="Privacy-first AI infrastructure"
  )

  embedding = response.data[0].embedding
  print(f"Vector dimension: {len(embedding)}")
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: process.env.VENICE_API_KEY,
      baseURL: 'https://api.venice.ai/api/v1'
  });

  async function main() {
      const response = await client.embeddings.create({
          model: 'text-embedding-bge-m3',
          input: 'Privacy-first AI infrastructure'
      });

      console.log(`Vector dimension: ${response.data[0].embedding.length}`);
  }

  main();
  ```

  ```bash cURL
  curl https://api.venice.ai/api/v1/embeddings \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "text-embedding-bge-m3",
      "input": "Privacy-first AI infrastructure"
    }'
  ```
</CodeGroup>

See the [Embeddings API](/api-reference/endpoint/embeddings/generate) for batch processing and advanced options.

### Vision (Multimodal)

Analyze images alongside text using vision-capable models like `mistral-31-24b`:

<CodeGroup>
  ```python Python
  import os
  from openai import OpenAI

  client = OpenAI(
      api_key=os.getenv("VENICE_API_KEY"),
      base_url="https://api.venice.ai/api/v1"
  )

  response = client.chat.completions.create(
      model="mistral-31-24b",
      messages=[
          {
              "role": "user",
              "content": [
                  {"type": "text", "text": "What is in this image?"},
                  {
                      "type": "image_url",
                      "image_url": {"url": "https://www.gstatic.com/webp/gallery/1.jpg"}
                  }
              ]
          }
      ]
  )

  print(response.choices[0].message.content)
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: process.env.VENICE_API_KEY,
      baseURL: 'https://api.venice.ai/api/v1'
  });

  async function main() {
      const response = await client.chat.completions.create({
          model: 'mistral-31-24b',
          messages: [
              {
                  role: 'user',
                  content: [
                      { type: 'text', text: 'What is in this image?' },
                      {
                          type: 'image_url',
                          image_url: { url: 'https://www.gstatic.com/webp/gallery/1.jpg' }
                      }
                  ]
              }
          ]
      });

      console.log(response.choices[0].message.content);
  }

  main();
  ```

  ```bash cURL
  curl https://api.venice.ai/api/v1/chat/completions \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "mistral-31-24b",
      "messages": [
        {
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "What is in this image?"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://www.gstatic.com/webp/gallery/1.jpg"
              }
            }
          ]
        }
      ]
    }'
  ```
</CodeGroup>

### Function Calling

Define functions that models can call to interact with external tools and APIs:

<CodeGroup>
  ```python Python
  import os
  from openai import OpenAI

  client = OpenAI(
      api_key=os.getenv("VENICE_API_KEY"),
      base_url="https://api.venice.ai/api/v1"
  )

  tools = [
      {
          "type": "function",
          "function": {
              "name": "get_weather",
              "description": "Get the current weather in a location",
              "parameters": {
                  "type": "object",
                  "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and state"
                      }
                  },
                  "required": ["location"]
              }
          }
      }
  ]

  response = client.chat.completions.create(
      model="llama-3.3-70b",
      messages=[{"role": "user", "content": "What's the weather in San Francisco?"}],
      tools=tools
  )

  print(response.choices[0].message)
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: process.env.VENICE_API_KEY,
      baseURL: 'https://api.venice.ai/api/v1'
  });

  const tools = [
      {
          type: 'function',
          function: {
              name: 'get_weather',
              description: 'Get the current weather in a location',
              parameters: {
                  type: 'object',
                  properties: {
                      location: {
                          type: 'string',
                          description: 'The city and state'
                      }
                  },
                  required: ['location']
              }
          }
      }
  ];

  const response = await client.chat.completions.create({
      model: 'llama-3.3-70b',
      messages: [{ role: 'user', content: "What's the weather in San Francisco?" }],
      tools: tools
  });

  console.log(response.choices[0].message);
  ```

  ```bash cURL
  curl https://api.venice.ai/api/v1/chat/completions \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "llama-3.3-70b",
      "messages": [
        {
          "role": "user",
          "content": "What'\''s the weather in San Francisco?"
        }
      ],
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_weather",
            "description": "Get the current weather in a location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state"
                }
              },
              "required": ["location"]
            }
          }
        }
      ]
    }'
  ```
</CodeGroup>

**Supported models:** `llama-3.3-70b`, `qwen3-235b`, `mistral-31-24b`, `qwen3-4b`

---

## Next Steps

Now that you've made your first requests, explore more of what Venice API has to offer:

<CardGroup cols={2}>
  <Card title="Browse Models" icon="database" href="/overview/models">
    Compare all available models with their capabilities, pricing, and context limits
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/api-spec">
    Explore detailed API documentation with all endpoints and parameters
  </Card>
  <Card title="Structured Responses" icon="brackets-curly" href="/overview/guides/structured-responses">
    Learn how to get JSON responses with guaranteed schemas
  </Card>
  <Card title="AI Agents Guide" icon="robot" href="/overview/guides/ai-agents">
    Build autonomous AI agents with Venice API and frameworks like Eliza
  </Card>
</CardGroup>

### Additional Resources

<CardGroup cols={2}>
  <Card title="Rate Limiting" icon="gauge" href="/api-reference/rate-limiting">
    Understand rate limits and best practices for production usage
  </Card>
  <Card title="Error Codes" icon="triangle-exclamation" href="/api-reference/error-codes">
    Reference for handling API errors and troubleshooting issues
  </Card>
  <Card title="Postman Collection" icon="bolt" href="/overview/guides/postman">
    Import our complete Postman collection for easy testing
  </Card>
  <Card title="Privacy & Security" icon="shield" href="/overview/privacy">
    Learn about Venice's privacy-first architecture and data handling
  </Card>
</CardGroup>

---

## Need Help?

- **Discord Community**: Join our [Discord server](https://discord.gg/askvenice) for support and discussions
- **Documentation**: Browse our [complete API reference](/api-reference/api-spec)
- **Status Page**: Check service status at [veniceai-status.com](https://veniceai-status.com)
- **Twitter**: Follow [@AskVenice](https://x.com/AskVenice) for updates

<Resources />
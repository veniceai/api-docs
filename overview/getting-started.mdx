---
title: Getting Started
"og:title": "Quickstart - Get started with Venice API"
description: "Make your first API request in minutes"
---

Venice AI is a privacy-first API for building AI applications with no data retention and OpenAI-compatible endpoints. You get text generation, image creation, embeddings, and text-to-speech without the surveillance.

## Quickstart

<Steps>
  <Step title="Get your API key">
    Head to your [Venice API Settings](https://venice.ai/settings/api) and generate a new API key.

    For a detailed walkthrough with screenshots, check out the [API Key guide](/overview/guides/generating-api-key).
  </Step>

  <Step title="Set up your API key">
    Add your API key to your environment. You can export it in your shell:

    ```bash
    export VENICE_API_KEY='your-api-key-here'
    ```

    Or add it to a `.env` file in your project:

    ```bash
    VENICE_API_KEY=your-api-key-here
    ```
  </Step>

  <Step title="Install the SDK (optional)">
    Venice is OpenAI-compatible, so you can use the OpenAI SDK or just call the API directly with cURL.

    <CodeGroup>
      ```bash Python
      pip install openai
      ```

      ```bash Node.js
      npm install openai
      ```
    </CodeGroup>
  </Step>

  <Step title="Send your first request">
    <CodeGroup>
      ```python Python
      from openai import OpenAI

      client = OpenAI(
          api_key="your-api-key-here",
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "system", "content": "You are a helpful AI assistant"},
              {"role": "user", "content": "Why is privacy important?"}
          ]
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      import OpenAI from 'openai';

      const client = new OpenAI({
          apiKey: 'your-api-key-here',
          baseURL: 'https://api.venice.ai/api/v1'
      });

      async function main() {
          const completion = await client.chat.completions.create({
              model: 'venice-uncensored',
              messages: [
                  { role: 'system', content: 'You are a helpful AI assistant' },
                  { role: 'user', content: 'Why is privacy important?' }
              ]
          });

          console.log(completion.choices[0].message.content);
      }

      main();
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "system", "content": "You are a helpful AI assistant"},
            {"role": "user", "content": "Why is privacy important?"}
          ]
        }'
      ```
    </CodeGroup>

    **Message roles:**
    - `system` - Instructions for how the model should behave
    - `user` - Your prompts or questions
    - `assistant` - Previous model responses (for multi-turn conversations)
    - `tool` - Function calling results (when using tools)
  </Step>

  <Step title="Choose your model (optional)">
    Venice has multiple models for different use cases. Popular choices:
    - `llama-3.3-70b` - Balanced performance, great for most use cases
    - `qwen3-235b` - Most powerful flagship model for complex tasks
    - `mistral-31-24b` - Vision + function calling support
    - `venice-uncensored` - No content filtering

    <Card title="View All Models" icon="database" href="/overview/models">
      Browse the complete list of models with pricing, capabilities, and context limits
    </Card>
  </Step>

  <Step title="Use Venice Parameters">
    You can choose to enable Venice-specific features like web search using `venice_parameters`:

    <CodeGroup>
      ```python Python
      from openai import OpenAI

      client = OpenAI(
          api_key="your-api-key-here",
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "user", "content": "What are the latest developments in AI?"}
          ],
          extra_body={
              "venice_parameters": {
                  "enable_web_search": "auto",
                  "include_venice_system_prompt": True
              }
          }
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      const response = await fetch('https://api.venice.ai/api/v1/chat/completions', {
          method: 'POST',
          headers: {
              'Authorization': 'Bearer your-api-key-here',
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              model: 'venice-uncensored',
              messages: [
                  { role: 'user', content: 'What are the latest developments in AI?' }
              ],
              venice_parameters: {
                  enable_web_search: 'auto',
                  include_venice_system_prompt: true
              }
          })
      });

      const result = await response.json();
      console.log(result.choices[0].message.content);
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
          "messages": [
            {"role": "user", "content": "What are the latest developments in AI?"}
          ],
          "venice_parameters": {
            "enable_web_search": "auto",
            "include_venice_system_prompt": true
          }
        }'
      ```
    </CodeGroup>

    See all [available parameters](/overview/about-venice#available-parameters).
  </Step>

  <Step title="Enable streaming (optional)">
    Stream responses in real-time using `stream=True`:

    <CodeGroup>
      ```python Python
      from openai import OpenAI

      client = OpenAI(
          api_key="your-api-key-here",
          base_url="https://api.venice.ai/api/v1"
      )

      stream = client.chat.completions.create(
          model="venice-uncensored",
          messages=[{"role": "user", "content": "Write a short story about AI"}],
          stream=True
      )

      for chunk in stream:
          if chunk.choices[0].delta.content is not None:
              print(chunk.choices[0].delta.content, end="")
      ```

      ```javascript Node.js
      import OpenAI from 'openai';

      const client = new OpenAI({
          apiKey: 'your-api-key-here',
          baseURL: 'https://api.venice.ai/api/v1'
      });

      const stream = await client.chat.completions.create({
          model: 'venice-uncensored',
          messages: [{ role: 'user', content: 'Write a short story about AI' }],
          stream: true
      });

      for await (const chunk of stream) {
          process.stdout.write(chunk.choices[0]?.delta?.content || '');
      }
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
       "messages": [
            {"role": "user", "content": "Write a short story about AI"}
          ],
          "stream": true
      }'
      ```
    </CodeGroup>
  </Step>

  <Step title="Customize response behavior (optional)">
    Control how the model responds with parameters like temperature, max tokens, and more:

    <CodeGroup>
      ```python Python
      from openai import OpenAI

      client = OpenAI(
          api_key="your-api-key-here",
          base_url="https://api.venice.ai/api/v1"
      )

      completion = client.chat.completions.create(
          model="venice-uncensored",
          messages=[
              {"role": "system", "content": "You are a creative storyteller"},
              {"role": "user", "content": "Tell me a creative story"}
          ],
          temperature=0.8,
          max_tokens=500,
          top_p=0.9,
          frequency_penalty=0.5,
          presence_penalty=0.5,
          extra_body={
              "venice_parameters": {
                  "include_venice_system_prompt": False
              }
          }
      )

      print(completion.choices[0].message.content)
      ```

      ```javascript Node.js
      const response = await fetch('https://api.venice.ai/api/v1/chat/completions', {
          method: 'POST',
          headers: {
              'Authorization': 'Bearer your-api-key-here',
              'Content-Type': 'application/json'
          },
          body: JSON.stringify({
              model: 'venice-uncensored',
              messages: [
                  { role: 'system', content: 'You are a creative storyteller' },
                  { role: 'user', content: 'Tell me a creative story' }
              ],
              temperature: 0.8,
              max_tokens: 500,
              top_p: 0.9,
              frequency_penalty: 0.5,
              presence_penalty: 0.5,
              venice_parameters: {
                  include_venice_system_prompt: false
              }
          })
      });

      const result = await response.json();
      console.log(result.choices[0].message.content);
      ```

      ```bash cURL
      curl https://api.venice.ai/api/v1/chat/completions \
        -H "Authorization: Bearer $VENICE_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
          "model": "venice-uncensored",
       "messages": [
            {"role": "system", "content": "You are a creative storyteller"},
            {"role": "user", "content": "Tell me a creative story"}
          ],
          "temperature": 0.8,
          "max_tokens": 500,
          "top_p": 0.9,
          "frequency_penalty": 0.5,
          "presence_penalty": 0.5,
          "stream": false,
          "venice_parameters": {
            "include_venice_system_prompt": false
          }
      }'
      ```
    </CodeGroup>

    Check out the [Chat Completions docs](/api-reference/endpoint/chat/completions) for more information on all supported parameters.
  </Step>
</Steps>

---

## More Capabilities

### Image Generation

Create images from text prompts using diffusion models:

<CodeGroup>
  ```bash cURL
  curl https://api.venice.ai/api/v1/image/generate \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "venice-sd35",
      "prompt": "A cyberpunk city with neon lights and rain",
      "width": 1024,
      "height": 1024,
      "steps": 30
    }'
  ```

  ```python Python
  import requests

  response = requests.post(
      "https://api.venice.ai/api/v1/image/generate",
      headers={
          "Authorization": "Bearer your-api-key-here",
          "Content-Type": "application/json"
      },
      json={
          "model": "venice-sd35",
          "prompt": "A cyberpunk city with neon lights and rain",
          "width": 1024,
          "height": 1024,
          "steps": 30
      }
  )

  result = response.json()
  # Image URL will be in result['data'][0]['url']
  ```

  ```javascript Node.js
  const response = await fetch('https://api.venice.ai/api/v1/image/generate', {
      method: 'POST',
      headers: {
          'Authorization': 'Bearer your-api-key-here',
          'Content-Type': 'application/json'
      },
      body: JSON.stringify({
          model: 'venice-sd35',
          prompt: 'A cyberpunk city with neon lights and rain',
          width: 1024,
          height: 1024,
          steps: 30
      })
  });

  const result = await response.json();
  // Image URL will be in result.data[0].url
  ```
</CodeGroup>

**Popular Image Models:**
- `qwen-image` - Highest quality image generation
- `venice-sd35` - Default choice with Eliza integration
- `flux-dev` - High-quality FLUX standard model

<Card title="View All Image Models" icon="image" href="/overview/models#image-models">
  See all available image models with pricing and capabilities
</Card>

See the [Image Generation API](/api-reference/endpoint/image/generate) for all parameters.

### Text-to-Speech

Convert text to audio with 60+ multilingual voices:

<CodeGroup>
  ```bash cURL
  curl https://api.venice.ai/api/v1/audio/speech \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "tts-kokoro",
      "input": "Privacy is a fundamental human right",
      "voice": "af_nova"
    }' \
    --output speech.mp3
  ```

  ```python Python
  import requests

  response = requests.post(
      "https://api.venice.ai/api/v1/audio/speech",
      headers={
          "Authorization": "Bearer your-api-key-here",
          "Content-Type": "application/json"
      },
      json={
          "model": "tts-kokoro",
          "input": "Privacy is a fundamental human right",
          "voice": "af_nova"
      }
  )

  with open("speech.mp3", "wb") as f:
      f.write(response.content)
  ```

  ```javascript Node.js
  const response = await fetch('https://api.venice.ai/api/v1/audio/speech', {
      method: 'POST',
      headers: {
          'Authorization': 'Bearer your-api-key-here',
          'Content-Type': 'application/json'
      },
      body: JSON.stringify({
          model: 'tts-kokoro',
          input: 'Privacy is a fundamental human right',
          voice: 'af_nova'
      })
  });

  const audioBuffer = await response.arrayBuffer();
  // Save or process the audio buffer
  ```
</CodeGroup>

The `tts-kokoro` model supports 60+ multilingual voices including `af_nova`, `am_liam`, `bf_emma`, `zf_xiaobei`, and `jm_kumo`.

See the [TTS API](/api-reference/endpoint/audio/speech) for all voice options.

### Embeddings

Generate vector embeddings for semantic search, RAG, and recommendations:

<CodeGroup>
  ```bash cURL
  curl https://api.venice.ai/api/v1/embeddings \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "text-embedding-bge-m3",
      "input": "Privacy-first AI infrastructure"
    }'
  ```

  ```python Python
  from openai import OpenAI

  client = OpenAI(
      api_key="your-api-key-here",
      base_url="https://api.venice.ai/api/v1"
  )

  response = client.embeddings.create(
      model="text-embedding-bge-m3",
      input="Privacy-first AI infrastructure"
  )

  embedding = response.data[0].embedding
  print(f"Vector dimension: {len(embedding)}")
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: 'your-api-key-here',
      baseURL: 'https://api.venice.ai/api/v1'
  });

  const response = await client.embeddings.create({
      model: 'text-embedding-bge-m3',
      input: 'Privacy-first AI infrastructure'
  });

  console.log(`Vector dimension: ${response.data[0].embedding.length}`);
  ```
</CodeGroup>

See the [Embeddings API](/api-reference/endpoint/embeddings/generate) for batch processing and advanced options.

### Vision (Multimodal)

Analyze images alongside text using vision-capable models like `mistral-31-24b`:

<CodeGroup>
  ```bash cURL
  curl https://api.venice.ai/api/v1/chat/completions \
    -H "Authorization: Bearer $VENICE_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "model": "mistral-31-24b",
      "messages": [
        {
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "What is in this image?"
            },
            {
              "type": "image_url",
              "image_url": {
                "url": "https://example.com/image.jpg"
              }
            }
          ]
        }
      ]
    }'
  ```

  ```python Python
  from openai import OpenAI

  client = OpenAI(
      api_key="your-api-key-here",
      base_url="https://api.venice.ai/api/v1"
  )

  response = client.chat.completions.create(
      model="mistral-31-24b",
      messages=[
          {
              "role": "user",
              "content": [
                  {"type": "text", "text": "What is in this image?"},
                  {
                      "type": "image_url",
                      "image_url": {"url": "https://example.com/image.jpg"}
                  }
              ]
          }
      ]
  )

  print(response.choices[0].message.content)
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: 'your-api-key-here',
      baseURL: 'https://api.venice.ai/api/v1'
  });

  const response = await client.chat.completions.create({
      model: 'mistral-31-24b',
      messages: [
          {
              role: 'user',
              content: [
                  { type: 'text', text: 'What is in this image?' },
                  {
                      type: 'image_url',
                      image_url: { url: 'https://example.com/image.jpg' }
                  }
              ]
          }
      ]
  });

  console.log(response.choices[0].message.content);
  ```
</CodeGroup>

### Function Calling

Define functions that models can call to interact with external tools and APIs:

<CodeGroup>
  ```python Python
  from openai import OpenAI

  client = OpenAI(
      api_key="your-api-key-here",
      base_url="https://api.venice.ai/api/v1"
  )

  tools = [
      {
          "type": "function",
          "function": {
              "name": "get_weather",
              "description": "Get the current weather in a location",
              "parameters": {
                  "type": "object",
                  "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and state"
                      }
                  },
                  "required": ["location"]
              }
          }
      }
  ]

  response = client.chat.completions.create(
      model="llama-3.3-70b",
      messages=[{"role": "user", "content": "What's the weather in San Francisco?"}],
      tools=tools
  )

  print(response.choices[0].message)
  ```

  ```javascript Node.js
  import OpenAI from 'openai';

  const client = new OpenAI({
      apiKey: 'your-api-key-here',
      baseURL: 'https://api.venice.ai/api/v1'
  });

  const tools = [
      {
          type: 'function',
          function: {
              name: 'get_weather',
              description: 'Get the current weather in a location',
              parameters: {
                  type: 'object',
                  properties: {
                      location: {
                          type: 'string',
                          description: 'The city and state'
                      }
                  },
                  required: ['location']
              }
          }
      }
  ];

  const response = await client.chat.completions.create({
      model: 'llama-3.3-70b',
      messages: [{ role: 'user', content: "What's the weather in San Francisco?" }],
      tools: tools
  });

  console.log(response.choices[0].message);
  ```
</CodeGroup>

**Supported models:** `llama-3.3-70b`, `qwen3-235b`, `mistral-31-24b`, `qwen3-4b`

---

## Next Steps

Now that you've made your first requests, explore more of what Venice API has to offer:

<CardGroup cols={2}>
  <Card title="Browse Models" icon="database" href="/overview/models">
    Compare all available models with their capabilities, pricing, and context limits
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/api-spec">
    Explore detailed API documentation with all endpoints and parameters
  </Card>
  <Card title="Structured Responses" icon="brackets-curly" href="/overview/guides/structured-responses">
    Learn how to get JSON responses with guaranteed schemas
  </Card>
  <Card title="AI Agents Guide" icon="robot" href="/overview/guides/ai-agents">
    Build autonomous AI agents with Venice API and frameworks like Eliza
  </Card>
</CardGroup>

### Additional Resources

<CardGroup cols={2}>
  <Card title="Rate Limiting" icon="gauge" href="/api-reference/rate-limiting">
    Understand rate limits and best practices for production usage
  </Card>
  <Card title="Error Codes" icon="triangle-exclamation" href="/api-reference/error-codes">
    Reference for handling API errors and troubleshooting issues
  </Card>
  <Card title="Postman Collection" icon="bolt" href="/overview/guides/postman">
    Import our complete Postman collection for easy testing
  </Card>
  <Card title="Privacy & Security" icon="shield" href="/overview/privacy">
    Learn about Venice's privacy-first architecture and data handling
  </Card>
</CardGroup>

---

## Need Help?

- **Discord Community**: Join our [Discord server](https://discord.gg/askvenice) for support and discussions
- **Documentation**: Browse our [complete API reference](/api-reference/api-spec)
- **Status Page**: Check service status at [veniceai-status.com](https://veniceai-status.com)
- **Twitter**: Follow [@AskVenice](https://x.com/AskVenice) for updates

<Resources />